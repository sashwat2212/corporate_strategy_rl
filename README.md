# <div align="center">ğŸ“ˆ Corporate Strategy RL</div>

## ğŸš€ Project Overview
This project implements an **agentic AI system** for **strategic corporate planning** using reinforcement learning (**Q-learning**).  
The system simulates business decisions in a **competitive market**, including:

âœ… **Investment Strategies**  
ğŸ“¢ **Marketing Campaigns**  
ğŸ’° **Pricing Adjustments**  
ğŸ¤ **Acquisitions and Mergers**  

> *The simulation evaluates agents based on total rewards, financial capital, and market share dynamics.*

---

## ğŸ—ï¸ Architecture

### ğŸ¢ 1. Environment (`env.py`)
- ğŸ¦ Defines the **corporate marketplace** with dynamic competition.
- ğŸ“Š Implements a **reward structure** based on revenue, capital growth, and market expansion.
- ğŸ“ˆ Tracks key **KPIs**: Total rewards, capital, and market share.

### ğŸ¤– 2. Agents (`agents.py`)
- ğŸ¯ Uses **Q-learning** for strategic decision-making.
- ğŸ”„ Implements **exploration-exploitation** balance.
- ğŸ“‰ Tracks **efficiency scores** to measure learning progress.

### ğŸ¬ 3. Simulations (`simulations.py`)
- ğŸ”„ Runs multiple training episodes (**default: 1000**).
- ğŸ“‚ Stores data on:
  - âœ… **Total rewards per agent**
  - ğŸ“ˆ **Capital growth trends**
  - ğŸ“Š **Market share evolution**
- ğŸ–¼ï¸ Generates and saves **visualizations** in the `output/` directory.

---

## ğŸ“Š Performance Results

### ğŸ”¥ 1. Agent Performance Over Episodes
- ğŸ“ˆ **Rewards start low (~200) but increase to ~450-500 per episode**, demonstrating successful learning.

### ğŸ’° 2. Capital Growth Analysis
- ğŸ“‰ Both agents initially **experience capital loss** but **stabilize around episode 900**.

### ğŸ“Š 3. Market Share Distribution
- ğŸ”„ Market share fluctuates but eventually **stabilizes near 100%**, requiring further analysis.

---

## ğŸ“ Efficiency Metrics
| Metric            | Value                 |
|------------------|----------------------|
| **Efficiency Score** | `50,000,000` (both agents) |
| **Market Share**    | `100%` (potential need for competitive adjustments) |

---

## ğŸš€ Next Steps for Improvement
ğŸ”§ **Optimize reward functions** to prevent capital depletion.  
âš–ï¸ **Enhance competitive behavior** to prevent unrealistic **100% market dominance**.  
âš¡ **Adjust Q-learning hyperparameters** for better decision-making efficiency.  

ğŸ“Š **Evaluate the impact of different market conditions** to create a more dynamic training environment.  
ğŸ”„ **Introduce adversarial strategies** to prevent agents from overfitting to specific conditions.  
